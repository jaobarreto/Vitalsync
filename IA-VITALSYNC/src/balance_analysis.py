"""
balance_analysis.py
------------------
Script para analisar o desbalanceamento de classes e seu impacto potencial no modelo.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path


def analyze_class_balance(df: pd.DataFrame):
    """
    Analisa o balanceamento de classes no dataset.
    """
    print("=" * 80)
    print("‚öñÔ∏è  AN√ÅLISE DE BALANCEAMENTO DE CLASSES")
    print("=" * 80)
    
    # Contar classes
    class_counts = df['label'].value_counts().sort_index()
    total = len(df)
    
    print(f"\nüìä DISTRIBUI√á√ÉO DAS CLASSES:")
    print("-" * 80)
    print(f"  Classe 0 (Ritmo Normal): {class_counts[0]:>3} registros ({class_counts[0]/total*100:>5.1f}%)")
    print(f"  Classe 1 (Fibrila√ß√£o Atrial): {class_counts[1]:>3} registros ({class_counts[1]/total*100:>5.1f}%)")
    print(f"  Total: {total} registros")
    
    # Calcular raz√£o de desbalanceamento
    minority_class = class_counts.min()
    majority_class = class_counts.max()
    imbalance_ratio = majority_class / minority_class
    
    print(f"\nüìê M√âTRICAS DE DESBALANCEAMENTO:")
    print("-" * 80)
    print(f"  Classe minorit√°ria: {minority_class} registros (Ritmo Normal)")
    print(f"  Classe majorit√°ria: {majority_class} registros (Fibrila√ß√£o Atrial)")
    print(f"  Raz√£o de desbalanceamento: {imbalance_ratio:.2f}:1")
    
    # Avaliar severidade do desbalanceamento
    print(f"\nüéØ AVALIA√á√ÉO DO DESBALANCEAMENTO:")
    print("-" * 80)
    
    if imbalance_ratio < 1.5:
        severity = "LEVE"
        color = "üü¢"
        impact = "M√≠nimo - O modelo deve funcionar bem sem ajustes especiais"
    elif imbalance_ratio < 3:
        severity = "MODERADO"
        color = "üü°"
        impact = "Baixo a M√©dio - Recomendado usar class_weight ou t√©cnicas de balanceamento"
    elif imbalance_ratio < 10:
        severity = "ALTO"
        color = "üü†"
        impact = "M√©dio a Alto - Necess√°rio usar t√©cnicas de balanceamento (SMOTE, class_weight, etc.)"
    else:
        severity = "SEVERO"
        color = "üî¥"
        impact = "Alto - Altamente recomendado usar m√∫ltiplas t√©cnicas de balanceamento"
    
    print(f"  {color} Severidade: {severity} ({imbalance_ratio:.2f}:1)")
    print(f"  {color} Impacto esperado: {impact}")
    
    return class_counts, imbalance_ratio


def explain_imbalance_impact():
    """
    Explica o impacto do desbalanceamento no modelo.
    """
    print("\n" + "=" * 80)
    print("üß† COMO O DESBALANCEAMENTO AFETA O MODELO DE ML")
    print("=" * 80)
    
    print("""
üìö CONCEITO:
   Quando um dataset est√° desbalanceado, o modelo tende a "favorecer" a classe 
   majorit√°ria porque ela aparece mais nos dados de treino.

üéØ NO NOSSO CASO (80 FA vs 18 Normal):

   PROBLEMA POTENCIAL:
   ‚Ä¢ O modelo pode ficar "viciado" em prever Fibrila√ß√£o Atrial
   ‚Ä¢ Ele pode aprender: "Na d√∫vida, classifique como FA"
   ‚Ä¢ Isso d√° uma acur√°cia alta (80%), mas √© ENGANOSO!

   ‚ùå EXEMPLO DE MODELO RUIM:
   
   Imagine um modelo "burro" que SEMPRE prev√™ FA (label=1):
   
   ‚Ä¢ Acur√°cia: 80/98 = 81.6% ‚úÖ (parece √≥timo!)
   ‚Ä¢ MAS ele NUNCA detecta Ritmo Normal ‚ùå
   ‚Ä¢ Sensibilidade (detectar FA): 100% ‚úÖ
   ‚Ä¢ Especificidade (detectar Normal): 0% ‚ùå P√âSSIMO!
   
   Este modelo √© IN√öTIL clinicamente, mas tem "boa acur√°cia"!

üí° POR QUE ISSO ACONTECE:

   Durante o treinamento, o modelo v√™:
   ‚Ä¢ 80 exemplos de FA ‚Üí "Aprende bem o que √© FA"
   ‚Ä¢ 18 exemplos de Normal ‚Üí "V√™ pouco e n√£o aprende direito"
   
   Resultado: Ele fica "expert em FA" mas "p√©ssimo em Normal"

üéØ IMPACTO NAS M√âTRICAS:

   ‚úÖ Acur√°cia: Pode ser enganosa (modelo ruim pode ter 80%+)
   ‚ö†Ô∏è  Sensibilidade (Recall para FA): Provavelmente ALTA (bom)
   ‚ùå Especificidade (detectar Normal): Provavelmente BAIXA (ruim)
   ‚ö†Ô∏è  Precis√£o: Pode ser moderada
   
   √â por isso que N√ÉO podemos confiar apenas na acur√°cia!
""")


def suggest_solutions(imbalance_ratio: float):
    """
    Sugere solu√ß√µes para lidar com o desbalanceamento.
    """
    print("\n" + "=" * 80)
    print("üí° SOLU√á√ïES PARA O DESBALANCEAMENTO")
    print("=" * 80)
    
    print(f"\nPara uma raz√£o de {imbalance_ratio:.2f}:1, recomendamos:\n")
    
    print("1Ô∏è‚É£  CLASS_WEIGHT='balanced' (MAIS F√ÅCIL - RECOMENDADO)")
    print("-" * 80)
    print("""
   O QUE FAZ:
   ‚Ä¢ D√° "pesos" diferentes para cada classe durante o treino
   ‚Ä¢ Exemplos da classe minorit√°ria (Normal) recebem peso MAIOR
   ‚Ä¢ For√ßa o modelo a prestar mais aten√ß√£o nos casos raros
   
   COMO USAR:
   ```python
   from sklearn.ensemble import RandomForestClassifier
   
   # Simples assim!
   modelo = RandomForestClassifier(class_weight='balanced')
   modelo.fit(X_train, y_train)
   ```
   
   VANTAGENS:
   ‚úÖ F√°cil de implementar (1 par√¢metro!)
   ‚úÖ Funciona bem para desbalanceamento moderado
   ‚úÖ N√£o precisa gerar dados artificiais
   
   DESVANTAGENS:
   ‚ö†Ô∏è  Pode n√£o ser suficiente para desbalanceamento severo (>10:1)
""")
    
    print("\n2Ô∏è‚É£  SMOTE - Synthetic Minority Over-sampling Technique")
    print("-" * 80)
    print("""
   O QUE FAZ:
   ‚Ä¢ Cria exemplos SINT√âTICOS da classe minorit√°ria
   ‚Ä¢ Usa interpola√ß√£o entre exemplos existentes
   ‚Ä¢ Aumenta o n√∫mero de casos de Ritmo Normal artificialmente
   
   COMO USAR:
   ```python
   from imblearn.over_sampling import SMOTE
   
   smote = SMOTE(random_state=42)
   X_balanced, y_balanced = smote.fit_resample(X_train, y_train)
   
   # Agora treina com dados balanceados
   modelo.fit(X_balanced, y_balanced)
   ```
   
   VANTAGENS:
   ‚úÖ Aumenta a quantidade de dados da classe minorit√°ria
   ‚úÖ Funciona bem para desbalanceamento alto
   ‚úÖ Modelo v√™ mais exemplos da classe rara
   
   DESVANTAGENS:
   ‚ö†Ô∏è  Pode gerar dados "irrealistas" (overfitting)
   ‚ö†Ô∏è  Precisa instalar biblioteca extra (imbalanced-learn)
""")
    
    print("\n3Ô∏è‚É£  UNDERSAMPLING (Reduzir classe majorit√°ria)")
    print("-" * 80)
    print("""
   O QUE FAZ:
   ‚Ä¢ Remove aleatoriamente exemplos da classe majorit√°ria (FA)
   ‚Ä¢ Deixa o dataset balanceado (ex: 18 FA vs 18 Normal)
   
   QUANDO USAR:
   ‚Ä¢ ‚ö†Ô∏è  N√ÉO RECOMENDADO no nosso caso!
   ‚Ä¢ Perder√≠amos 62 dos 80 exemplos de FA
   ‚Ä¢ Com apenas 36 exemplos totais, o modelo ficaria MUITO fraco
   
   VANTAGENS:
   ‚úÖ Balanceamento perfeito
   ‚úÖ Treino mais r√°pido (menos dados)
   
   DESVANTAGENS:
   ‚ùå PERDE muitos dados valiosos
   ‚ùå Modelo treina com menos informa√ß√£o
   ‚ùå N√£o recomendado para datasets pequenos como o nosso
""")
    
    print("\n4Ô∏è‚É£  M√âTRICAS APROPRIADAS (ESSENCIAL!)")
    print("-" * 80)
    print("""
   SEMPRE USE:
   ‚Ä¢ ‚úÖ Sensibilidade (Recall) - Detectar FA corretamente
   ‚Ä¢ ‚úÖ Especificidade - Detectar Normal corretamente
   ‚Ä¢ ‚úÖ F1-Score - Balanceia Precis√£o e Recall
   ‚Ä¢ ‚úÖ ROC-AUC - M√©trica geral robusta a desbalanceamento
   ‚Ä¢ ‚úÖ Matriz de Confus√£o - Ver onde o modelo erra
   
   EVITE:
   ‚Ä¢ ‚ùå Acur√°cia sozinha (√© enganosa!)
""")
    
    print("\n5Ô∏è‚É£  STRATIFIED K-FOLD (Para valida√ß√£o)")
    print("-" * 80)
    print("""
   O QUE FAZ:
   ‚Ä¢ Divide dados de treino/teste mantendo a propor√ß√£o de classes
   ‚Ä¢ Garante que ambas as classes aparecem no teste
   
   COMO USAR:
   ```python
   from sklearn.model_selection import train_test_split
   
   # stratify=y mant√©m a propor√ß√£o de classes
   X_train, X_test, y_train, y_test = train_test_split(
       X, y, test_size=0.2, stratify=y, random_state=42
   )
   ```
   
   VANTAGENS:
   ‚úÖ Garante representa√ß√£o justa de ambas as classes
   ‚úÖ Avalia√ß√£o mais confi√°vel
""")


def recommend_approach(imbalance_ratio: float):
    """
    Recomenda a melhor abordagem para o projeto.
    """
    print("\n" + "=" * 80)
    print("üéØ RECOMENDA√á√ÉO PARA O SEU PROJETO")
    print("=" * 80)
    
    print(f"""
Dado que temos uma raz√£o de {imbalance_ratio:.2f}:1, recomendo a seguinte estrat√©gia:

üìã PLANO DE A√á√ÉO:

1. ‚úÖ USAR class_weight='balanced'
   ‚Üí Aplicar em TODOS os modelos (Random Forest, SVM, etc.)
   ‚Üí √â simples e eficaz para nosso n√≠vel de desbalanceamento

2. ‚úÖ USAR stratify no train_test_split
   ‚Üí Garante que o conjunto de teste seja representativo

3. ‚úÖ AVALIAR com m√©tricas apropriadas
   ‚Üí Sensibilidade, Especificidade, F1-Score, ROC-AUC
   ‚Üí N√ÉO confiar apenas na acur√°cia

4. ‚è≥ TESTAR SMOTE (opcional)
   ‚Üí Se class_weight n√£o for suficiente
   ‚Üí Comparar resultados com e sem SMOTE

5. ‚úÖ CRIAR matriz de confus√£o detalhada
   ‚Üí Ver exatamente onde o modelo erra
   ‚Üí Verificar se ele "vicia" em prever FA

üìä EXPECTATIVA REALISTA:

Com class_weight='balanced':
‚Ä¢ ‚úÖ Sensibilidade (detectar FA): 85-95%
‚Ä¢ ‚úÖ Especificidade (detectar Normal): 70-85%
‚Ä¢ ‚úÖ ROC-AUC: 0.85-0.95

Sem balanceamento:
‚Ä¢ ‚úÖ Sensibilidade (detectar FA): 95-100% (muito alta)
‚Ä¢ ‚ùå Especificidade (detectar Normal): 30-50% (ruim!)
‚Ä¢ ‚ö†Ô∏è  ROC-AUC: 0.70-0.80 (moderado)

üéì CONCLUS√ÉO:

O desbalanceamento de {imbalance_ratio:.2f}:1 √© GERENCI√ÅVEL com as t√©cnicas certas!
N√ÉO √© severo o suficiente para impedir bons resultados.

A chave √©:
1. Usar class_weight='balanced'
2. Avaliar com m√©tricas corretas
3. N√£o confiar s√≥ na acur√°cia

Vamos implementar isso no pr√≥ximo passo! üöÄ
""")


def visualize_imbalance(df: pd.DataFrame):
    """
    Cria visualiza√ß√µes do desbalanceamento.
    """
    print("\n" + "=" * 80)
    print("üìä GERANDO VISUALIZA√á√ïES...")
    print("=" * 80)
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Gr√°fico de barras
    class_counts = df['label'].value_counts().sort_index()
    labels_text = ['Ritmo Normal\n(Classe 0)', 'Fibrila√ß√£o Atrial\n(Classe 1)']
    colors = ['#2ecc71', '#e74c3c']
    
    axes[0].bar(labels_text, class_counts.values, color=colors, edgecolor='black', linewidth=2)
    axes[0].set_ylabel('N√∫mero de Registros', fontsize=12)
    axes[0].set_title('Distribui√ß√£o de Classes', fontsize=14, fontweight='bold')
    axes[0].grid(True, alpha=0.3, axis='y')
    
    # Adicionar n√∫meros nas barras
    for i, (label, count) in enumerate(zip(labels_text, class_counts.values)):
        axes[0].text(i, count + 2, f'{count}\n({count/len(df)*100:.1f}%)', 
                    ha='center', fontsize=11, fontweight='bold')
    
    # Gr√°fico de pizza
    axes[1].pie(class_counts.values, labels=labels_text, autopct='%1.1f%%',
               colors=colors, startangle=90, textprops={'fontsize': 11, 'fontweight': 'bold'},
               wedgeprops={'edgecolor': 'black', 'linewidth': 2})
    axes[1].set_title('Propor√ß√£o de Classes', fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    
    # Salvar figura
    output_dir = Path(__file__).parent.parent / 'reports' / 'figures'
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / 'class_imbalance.png'
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"\nüíæ Visualiza√ß√£o salva em: {output_file}")
    
    plt.show()


if __name__ == "__main__":
    # Carregar dados
    features_path = Path(__file__).parent.parent / 'data' / 'processed' / 'features.csv'
    df = pd.read_csv(features_path)
    
    # An√°lise
    class_counts, imbalance_ratio = analyze_class_balance(df)
    explain_imbalance_impact()
    suggest_solutions(imbalance_ratio)
    recommend_approach(imbalance_ratio)
    visualize_imbalance(df)
    
    print("\n" + "=" * 80)
    print("‚úÖ AN√ÅLISE COMPLETA!")
    print("=" * 80)
